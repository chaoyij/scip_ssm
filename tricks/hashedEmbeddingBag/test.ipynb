{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import hashedEmbeddingBag"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "bag_num = 18\n",
    "\n",
    "num_categories = 100\n",
    "num_feature = 200\n",
    "\n",
    "hashed_weight_size = 200"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "hashed_weights = torch.rand(hashed_weight_size)\n",
    "#hashed_weights = torch.arange(start=0, end=hashed_weight_size, dtype=torch.float)\n",
    "bag_size = torch.randint(low=0, high=7, size=(bag_num,))\n",
    "indices_num = bag_size.sum().item()\n",
    "\n",
    "indices = torch.randint(low=0, high=num_categories - 1, size=(indices_num, ))\n",
    "offsets = torch.cat([torch.zeros(1, dtype=torch.long), bag_size.cumsum(dim=0)[:-1]])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m&lt;ipython-input-11-488523edab43&gt;\u001b[0m in \u001b[0;36m&lt;module&gt;\u001b[0;34m\u001b[0m\n\u001b[0;32m----&gt; 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhash_embedding_bag\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHashEmbeddingBag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrand_hash_compression_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mEE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHashEmbeddingBag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_categories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrand_hash_compression_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m&quot;sum&quot;\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m W = np.random.uniform(\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "from ..hash_embedding_bag import HashEmbeddingBag\n",
    "rand_hash_compression_rate = 1.0\n",
    "EE = HashEmbeddingBag(num_categories, num_feature, rand_hash_compression_rate, mode=\"sum\", sparse=True) \n",
    "\n",
    "W = np.random.uniform(\n",
    "    low=-np.sqrt(1 / num_categories), high=np.sqrt(1 / num_categories), size=((int(num_categories * num_feature * rand_hash_compression_rate), ))\n",
    ").astype(np.float32)\n",
    "\n",
    "EE.hashed_weight.data = torch.tensor(W, requires_grad=True)\n",
    "\n",
    "res = EE(indices, offsets)\n",
    "# res.retain_grad()\n",
    "tmp = res * torch.rand_like(res)\n",
    "y = tmp.sum()\n",
    "y.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([0.0742, 0.5512, 0.7735, 0.0277, 0.5534, 0.6312, 0.9595, 0.6147, 0.5786,\n        0.4998, 0.1227, 0.1964, 0.8471, 0.4832, 0.8912, 0.0355, 0.1091, 0.3957,\n        0.7282, 0.0337, 0.8541, 0.3468, 0.0627, 0.1448, 0.9559, 0.5573, 0.5869,\n        0.9164, 0.9378, 0.0108, 0.9261, 0.0148, 0.1056, 0.7051, 0.5944, 0.5668,\n        0.9488, 0.9400, 0.8657, 0.1544, 0.2546, 0.7715, 0.6750, 0.0532, 0.1054,\n        0.2850, 0.2631, 0.1623, 0.6379, 0.6976, 0.3825, 0.5741, 0.0321, 0.9194,\n        0.1473, 0.8829, 0.1773, 0.7017, 0.3858, 0.2094, 0.1253, 0.0628, 0.7051,\n        0.0650, 0.5395, 0.1520, 0.2271, 0.3845, 0.9135, 0.5561, 0.5906, 0.6283,\n        0.2852, 0.7947, 0.2883, 0.9424, 0.6395, 0.4158, 0.9134, 0.3668, 0.9611,\n        0.5433, 0.9668, 0.2631, 0.6407, 0.7282, 0.6691, 0.2924, 0.5423, 0.9734,\n        0.5553, 0.6706, 0.6026, 0.9388, 0.8802, 0.8003, 0.3522, 0.6272, 0.2924,\n        0.8819, 0.7676, 0.7061, 0.8722, 0.1206, 0.0156, 0.5838, 0.8999, 0.6155,\n        0.1820, 0.0061, 0.6635, 0.9971, 0.6967, 0.5787, 0.6847, 0.8667, 0.8123,\n        0.9027, 0.4604, 0.4503, 0.8455, 0.6377, 0.4130, 0.3911, 0.2491, 0.1996,\n        0.7547, 0.7268, 0.4699, 0.5710, 0.4255, 0.7070, 0.5193, 0.8093, 0.2966,\n        0.3106, 0.3396, 0.3030, 0.4911, 0.4817, 0.5478, 0.0087, 0.6473, 0.7699,\n        0.4302, 0.4108, 0.9069, 0.8067, 0.0455, 0.7746, 0.3474, 0.2047, 0.1830,\n        0.5141, 0.4848, 0.5050, 0.2854, 0.9952, 0.5990, 0.8383, 0.4454, 0.7193,\n        0.7156, 0.7162, 0.3857, 0.7650, 0.3251, 0.5768, 0.4256, 0.8769, 0.0194,\n        0.5129, 0.3916, 0.5576, 0.9765, 0.0689, 0.5453, 0.8494, 0.9764, 0.7981,\n        0.4540, 0.6378, 0.1651, 0.2934, 0.9268, 0.8401, 0.1143, 0.8072, 0.2822,\n        0.6992, 0.6803, 0.8932, 0.1125, 0.8858, 0.2862, 0.3415, 0.4727, 0.0817,\n        0.9902, 0.0416])\n"
    }
   ],
   "source": [
    "print(hashed_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([3, 2, 2, 5, 4, 0, 3, 5, 3, 2, 3, 6, 4, 0, 6, 4, 6, 6])\ntensor([31, 87, 65, 22, 36, 88, 87, 67, 40, 39, 83, 69, 69,  9, 61, 81,  3, 85,\n        54, 12, 27, 34, 23, 56, 90, 97, 70, 30, 34, 72, 82, 75,  0,  6, 90, 25,\n         3, 80,  6, 39, 83, 19, 22, 39, 18, 15, 75, 75, 46, 84, 84, 63, 81, 77,\n        71, 61,  4, 26, 39, 39,  3, 83, 88, 36])\ntensor([ 0,  3,  5,  7, 12, 16, 16, 19, 24, 27, 29, 32, 38, 42, 42, 48, 52, 58])\n64\n"
    }
   ],
   "source": [
    "print(bag_size)\n",
    "print(indices)\n",
    "print(offsets)\n",
    "print(indices_num)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([64])\n"
    }
   ],
   "source": [
    "print(indices.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "mode = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name &#39;hashed_embedding_bag_cpp&#39; is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m&lt;ipython-input-5-297cb373c13b&gt;\u001b[0m in \u001b[0;36m&lt;module&gt;\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset2bag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbag_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhashed_idx\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----&gt; 7\u001b[0;31m     \u001b[0mhashed_embedding_bag_cpp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhashed_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name &#39;hashed_embedding_bag_cpp&#39; is not defined"
     ]
    }
   ],
   "source": [
    "device = torch.cuda.current_device()\n",
    "hashed_weights = hashed_weights.to(device)\n",
    "indices = indices.to(device)\n",
    "offsets = offsets.to(device)\n",
    "\n",
    "output, offset2bag, bag_size, max_indices, hashed_idx = \\\n",
    "    hashed_embedding_bag_cpp.forward(hashed_weights, indices, offsets, mode, num_feature)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output is:\n",
      "tensor([[2.5495, 2.7259, 1.3040,  ..., 3.4254, 1.7057, 2.5805],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.9922, 0.9763, 0.7865,  ..., 1.2281, 0.8871, 0.9155],\n",
      "        ...,\n",
      "        [1.5951, 1.4250, 1.3399,  ..., 0.4097, 1.1818, 0.5418],\n",
      "        [0.5286, 1.2501, 0.1428,  ..., 0.5515, 1.3254, 1.3089],\n",
      "        [3.6974, 3.6964, 3.7366,  ..., 2.8123, 2.9436, 1.4833]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"output is:\")\n",
    "print(output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offset2bag is:\n",
      "tensor([ 0,  0,  0,  0,  0,  2,  2,  3,  4,  4,  4,  4,  4,  4,  5,  5,  5,  6,\n",
      "         6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  8,  8,  9,  9,  9,  9,  9,\n",
      "         9, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 13, 13, 13, 13, 14, 15, 15,\n",
      "        16, 16, 17, 17, 17, 17, 17, 17], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"offset2bag is:\")\n",
    "print(offset2bag)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag_size is:\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"bag_size is:\")\n",
    "print(bag_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_indices is:\n",
      "tensor([], device='cuda:0', size=(0, 0), dtype=torch.int64)\n"
     ]
    }
   ],
   "source": [
    "print(\"max_indices is:\")\n",
    "print(max_indices)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hashed_idx is:\n",
      "tensor([[ 96, 123, 150,  ..., 112, 139, 167],\n",
      "        [141, 168, 195,  ..., 157, 184,  12],\n",
      "        [195,  22,  49,  ...,  11,  38,  66],\n",
      "        ...,\n",
      "        [ 99, 126, 153,  ..., 115, 142, 170],\n",
      "        [154, 181,   8,  ..., 170, 197,  25],\n",
      "        [159, 186,  13,  ..., 175,   2,  30]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"hashed_idx is:\")\n",
    "print(hashed_idx)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([62, 200])\n"
     ]
    }
   ],
   "source": [
    "print(hashed_idx.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def toSignedInt(value, bits):\n",
    "    valueUint8 = value & (2**bits - 1)\n",
    "    if valueUint8 & 2**(bits-1):\n",
    "       return valueUint8 - 2**bits\n",
    "    return valueUint8\n",
    "\"\"\"\n",
    "def hash_function(a, b):\n",
    "    tmp1 = toSignedInt(a * 9824516537, 64)\n",
    "    tmp2 = toSignedInt(b * 57857966300227, 64)\n",
    "    tmp3 = toSignedInt(tmp1 + tmp2, 64)\n",
    "    tmp3 %= 117130198221199\n",
    "    return tmp3\n",
    "\"\"\"\n",
    "def hash_function(a, b):\n",
    "    return a + b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "hashed_weights = hashed_weights.to(device)\n",
    "indices = indices.to(device)\n",
    "offsets = offsets.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "output = output.to(device)\n",
    "offset2bag = offset2bag.to(device)\n",
    "bag_size = bag_size.to(device)\n",
    "max_indices = max_indices.to(device)\n",
    "hashed_idx = hashed_idx.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def make_offset2bag(offsets, indices):\n",
    "    offsets2bag = torch.zeros(indices.size(0) + 1, dtype=indices.dtype, device=offsets.device)\n",
    "    offsets2bag.index_add_(0, offsets, torch.ones_like(offsets, memory_format=torch.legacy_contiguous_format))\n",
    "    offsets2bag[0] -= 1\n",
    "    offsets2bag = offsets2bag.cumsum(0)\n",
    "    offsets2bag.resize_(indices.size(0))\n",
    "    return offsets2bag"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "expected_offsets2bag = make_offset2bag(offsets, indices)\n",
    "assert((expected_offsets2bag - offset2bag).abs().sum().item() == 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "expected_hashed_index = torch.zeros((indices_num, num_feature), dtype=torch.long)\n",
    "expected_output = torch.zeros(bag_num, num_feature)\n",
    "for i in range(indices.size(0)):\n",
    "    for j in range(num_feature):\n",
    "        weight_idx = hashed_embedding_bag_cpp.hash(indices[i].item(), j) % hashed_weights.size(0)\n",
    "        expected_hashed_index[i, j] = weight_idx\n",
    "        expected_output[expected_offsets2bag[i].item(), j] += hashed_weights[weight_idx]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.5495, 2.7259, 1.3040,  ..., 3.4254, 1.7057, 2.5805],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.9922, 0.9763, 0.7865,  ..., 1.2281, 0.8871, 0.9155],\n",
      "        ...,\n",
      "        [1.5951, 1.4250, 1.3399,  ..., 0.4097, 1.1818, 0.5418],\n",
      "        [0.5286, 1.2501, 0.1428,  ..., 0.5515, 1.3254, 1.3089],\n",
      "        [3.6974, 3.6964, 3.7366,  ..., 2.8123, 2.9436, 1.4833]])\n"
     ]
    }
   ],
   "source": [
    "print(expected_output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "assert(expected_hashed_index.equal(hashed_idx))\n",
    "assert(expected_output.equal(output))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "output_grad = torch.rand_like(expected_output)\n",
    "#output_grad = torch.arange(start=0, end=num_feature, dtype=torch.float).unsqueeze(0).repeat(bag_num, 1)\n",
    "#output_grad = torch.arange(start=0, end=bag_num, dtype=torch.float).unsqueeze(-1).repeat(1, num_feature)\n",
    "\n",
    "output_grad[:, 0] = 0.5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "expected_weight_grad = torch.zeros_like(hashed_weights)\n",
    "for i in range(indices.size(0)):\n",
    "    for j in range(num_feature):\n",
    "        weight_idx = hashed_embedding_bag_cpp.hash(indices[i].item(), j) % hashed_weights.size(0)\n",
    "        expected_weight_grad[weight_idx] += output_grad[offset2bag[i].item(), j]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "device = torch.cuda.current_device()\n",
    "hashed_weights = hashed_weights.to(device)\n",
    "indices = indices.to(device)\n",
    "offsets = offsets.to(device)\n",
    "offset2bag = offset2bag.to(device)\n",
    "bag_size = bag_size.to(device)\n",
    "max_indices = max_indices.to(device)\n",
    "hashed_idx = hashed_idx.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000, 0.3796, 0.1999,  ..., 0.8967, 0.4053, 0.3665],\n",
      "        [0.5000, 0.5629, 0.7411,  ..., 0.2909, 0.3786, 0.4533],\n",
      "        [0.5000, 0.0049, 0.9356,  ..., 0.9679, 0.2347, 0.5655],\n",
      "        ...,\n",
      "        [0.5000, 0.7635, 0.6262,  ..., 0.0303, 0.6782, 0.6878],\n",
      "        [0.5000, 0.8902, 0.3326,  ..., 0.4067, 0.1555, 0.5696],\n",
      "        [0.5000, 0.8377, 0.9889,  ..., 0.5755, 0.1353, 0.7145]])\n"
     ]
    }
   ],
   "source": [
    "print(output_grad)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "output_grad = output_grad.to(device)\n",
    "weight_grad = hashed_embedding_bag.backward(\n",
    "    output_grad, indices, offsets, offset2bag, bag_size, max_indices, hashed_idx, hashed_weights.size(0), False, mode, num_feature)\n",
    "weight_grad = weight_grad.cpu()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([27.8060, 37.2749, 28.3390, 28.5040, 35.0896, 27.6691, 34.2967, 27.0006,\n",
      "        30.2893, 34.8951, 25.1916, 34.3260, 31.2380, 32.2958, 34.8828, 21.5368,\n",
      "        39.0195, 34.7657, 29.3103, 37.0372, 21.9624, 34.5258, 30.2695, 22.3308,\n",
      "        34.0931, 25.3380, 35.0010, 31.4020, 30.9855, 35.7121, 23.6572, 34.4090,\n",
      "        30.6626, 28.6800, 35.8291, 26.2544, 37.2066, 31.3558, 22.1169, 35.4397,\n",
      "        25.3396, 37.4082, 30.6223, 24.3011, 41.3767, 22.6265, 36.7866, 28.8963,\n",
      "        30.2614, 35.3792, 26.4805, 35.5263, 31.8480, 31.5340, 34.0558, 26.2993,\n",
      "        39.1861, 32.6980, 24.8585, 35.9554, 23.3136, 36.0605, 24.9011, 29.2936,\n",
      "        36.0588, 23.2527, 38.1848, 31.1847, 31.3241, 31.9540, 21.9563, 36.2847,\n",
      "        30.9544, 28.8849, 40.6494, 23.8575, 36.7806, 34.8625, 25.3975, 39.7284,\n",
      "        26.2064, 33.7832, 29.0906, 27.0842, 38.3097, 28.1572, 33.3044, 28.9422,\n",
      "        31.1652, 36.7883, 25.9017, 38.4808, 30.6941, 29.1514, 31.3988, 23.5577,\n",
      "        36.9976, 29.1644, 26.5245, 44.7776, 27.1320, 30.2892, 28.6679, 29.2324,\n",
      "        37.4697, 27.0237, 32.0631, 35.6686, 27.0862, 40.3855, 27.0951, 35.5679,\n",
      "        34.0682, 25.4618, 38.7873, 26.0358, 35.7680, 27.4661, 31.7194, 35.4445,\n",
      "        23.2392, 33.2253, 26.9505, 33.0043, 38.0638, 24.6197, 40.3498, 34.4331,\n",
      "        27.9554, 41.9891, 26.0736, 37.5773, 31.3720, 23.5051, 41.4220, 24.0120,\n",
      "        33.3336, 29.4280, 27.9892, 35.7598, 23.4103, 27.7966, 30.5937, 30.8462,\n",
      "        41.1075, 27.7033, 35.1143, 28.0072, 29.0478, 34.6967, 27.4507, 39.2261,\n",
      "        28.9365, 28.2865, 41.8878, 19.0507, 36.6099, 29.7332, 32.4363, 43.2884,\n",
      "        24.6262, 39.5793, 36.4166, 26.4000, 33.6701, 26.2051, 38.4433, 29.2947,\n",
      "        29.2568, 34.3336, 28.9797, 37.0151, 27.7556, 30.4351, 36.6578, 28.2359,\n",
      "        34.5474, 29.0942, 28.8511, 34.3673, 28.3465, 38.2725, 29.9358, 24.8990,\n",
      "        39.0412, 22.8657, 38.9930, 28.5912, 28.1242, 39.9085, 25.1167, 32.4467,\n",
      "        24.4247, 23.9481, 37.2743, 23.6502, 33.7267, 29.1793, 29.5506, 35.3736])\n",
      "tensor([27.8060, 37.2749, 28.3390, 28.5040, 35.0896, 27.6691, 34.2967, 27.0006,\n",
      "        30.2893, 34.8951, 25.1916, 34.3260, 31.2380, 32.2958, 34.8828, 21.5368,\n",
      "        39.0195, 34.7657, 29.3103, 37.0372, 21.9624, 34.5258, 30.2695, 22.3308,\n",
      "        34.0931, 25.3380, 35.0010, 31.4020, 30.9855, 35.7121, 23.6572, 34.4090,\n",
      "        30.6626, 28.6800, 35.8291, 26.2544, 37.2066, 31.3558, 22.1169, 35.4397,\n",
      "        25.3396, 37.4082, 30.6223, 24.3011, 41.3767, 22.6265, 36.7866, 28.8963,\n",
      "        30.2614, 35.3792, 26.4805, 35.5263, 31.8480, 31.5340, 34.0558, 26.2993,\n",
      "        39.1861, 32.6980, 24.8585, 35.9554, 23.3136, 36.0605, 24.9011, 29.2936,\n",
      "        36.0588, 23.2527, 38.1848, 31.1847, 31.3241, 31.9540, 21.9563, 36.2847,\n",
      "        30.9544, 28.8849, 40.6494, 23.8575, 36.7806, 34.8625, 25.3975, 39.7284,\n",
      "        26.2064, 33.7832, 29.0906, 27.0842, 38.3097, 28.1572, 33.3044, 28.9422,\n",
      "        31.1652, 36.7883, 25.9017, 38.4808, 30.6941, 29.1514, 31.3988, 23.5577,\n",
      "        36.9976, 29.1644, 26.5245, 44.7776, 27.1320, 30.2892, 28.6679, 29.2324,\n",
      "        37.4697, 27.0237, 32.0631, 35.6686, 27.0862, 40.3855, 27.0951, 35.5679,\n",
      "        34.0682, 25.4618, 38.7873, 26.0358, 35.7680, 27.4661, 31.7194, 35.4445,\n",
      "        23.2392, 33.2253, 26.9505, 33.0043, 38.0638, 24.6197, 40.3498, 34.4331,\n",
      "        27.9554, 41.9891, 26.0736, 37.5773, 31.3720, 23.5051, 41.4220, 24.0120,\n",
      "        33.3336, 29.4280, 27.9892, 35.7598, 23.4103, 27.7966, 30.5937, 30.8462,\n",
      "        41.1075, 27.7033, 35.1143, 28.0072, 29.0478, 34.6967, 27.4507, 39.2261,\n",
      "        28.9365, 28.2865, 41.8878, 19.0507, 36.6099, 29.7332, 32.4363, 43.2884,\n",
      "        24.6262, 39.5793, 36.4166, 26.4000, 33.6701, 26.2051, 38.4433, 29.2947,\n",
      "        29.2568, 34.3336, 28.9797, 37.0151, 27.7556, 30.4351, 36.6578, 28.2359,\n",
      "        34.5474, 29.0942, 28.8511, 34.3673, 28.3465, 38.2725, 29.9358, 24.8990,\n",
      "        39.0412, 22.8657, 38.9930, 28.5912, 28.1242, 39.9085, 25.1167, 32.4467,\n",
      "        24.4247, 23.9481, 37.2743, 23.6502, 33.7267, 29.1793, 29.5506, 35.3736])\n"
     ]
    }
   ],
   "source": [
    "print(expected_weight_grad)\n",
    "print(weight_grad)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "assert((weight_grad - expected_weight_grad).sum().item() < 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "import hashedEmbeddingBag\n",
    "\n",
    "emb = hashedEmbeddingBag.HashedEmbeddingBag(\n",
    "    num_categories, num_feature, hashed_weight_size / (num_feature * num_categories), \"sum\", hashed_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "res = emb(indices, offsets)\n",
    "res.retain_grad()\n",
    "tmp = res * torch.rand_like(res)\n",
    "y = tmp.sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "y.backward()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.8299, 0.3449, 0.4369,  ..., 0.2575, 0.6161, 0.2326],\n        [0.2031, 0.6160, 0.0304,  ..., 0.4137, 0.8672, 0.9687],\n        [0.5426, 0.2544, 0.4731,  ..., 0.1255, 0.5904, 0.2212],\n        ...,\n        [0.5786, 0.1521, 0.6528,  ..., 0.0132, 0.9859, 0.4594],\n        [0.3869, 0.1114, 0.4772,  ..., 0.5867, 0.7003, 0.6562],\n        [0.6193, 0.5987, 0.6355,  ..., 0.7297, 0.5350, 0.3156]],\n       device='cuda:0')"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.grad"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "assert(res.cpu().equal(expected_output))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "output_grad = res.grad\n",
    "weight_grad = hashed_embedding_bag.backward(\n",
    "    output_grad, indices, offsets, offset2bag, bag_size, max_indices, hashed_idx, hashed_weights.size(0), False, mode, num_feature)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([28.6647, 33.7771, 30.8297, 26.1920, 37.2349, 22.1958, 40.1617, 23.8646,\n",
      "        30.3030, 37.6175, 25.3539, 37.1051, 26.2893, 27.4369, 38.2938, 19.4628,\n",
      "        33.0944, 30.6701, 26.2642, 34.5083, 26.7415, 38.6326, 31.5370, 24.7241,\n",
      "        36.2476, 24.5748, 30.7943, 27.1417, 26.1520, 38.9264, 24.7804, 34.5055,\n",
      "        27.8081, 34.1135, 33.0762, 28.1730, 39.0989, 30.2885, 25.6206, 36.7191,\n",
      "        22.0160, 37.4300, 26.4427, 26.2944, 37.8319, 22.2111, 36.2036, 28.3697,\n",
      "        26.0551, 39.0857, 24.2064, 32.1506, 33.2219, 30.1717, 31.4831, 27.5775,\n",
      "        31.1823, 26.8256, 24.7222, 28.5772, 28.3907, 42.9492, 24.8194, 31.8911,\n",
      "        37.9581, 22.6663, 36.5941, 27.6358, 33.3060, 37.4050, 22.5016, 40.2579,\n",
      "        34.9055, 24.9475, 36.3019, 19.8485, 37.4923, 34.6698, 28.3726, 37.3526,\n",
      "        26.4358, 38.5773, 23.5011, 25.2657, 37.1592, 26.5228, 35.8970, 28.1351,\n",
      "        27.9438, 37.3608, 23.0288, 36.6272, 29.6169, 27.2690, 41.5527, 24.6608,\n",
      "        38.5049, 30.4079, 29.6925, 42.2579, 23.6457, 35.1631, 30.4932, 27.6084,\n",
      "        37.4493, 27.5272, 30.0957, 38.5720, 23.8400, 39.9373, 26.3231, 29.5085,\n",
      "        30.4950, 20.5622, 34.5980, 21.8973, 37.5721, 27.8414, 33.2064, 41.0268,\n",
      "        23.9534, 32.2890, 27.2671, 30.4309, 33.9289, 20.7031, 35.8364, 34.7979,\n",
      "        24.9476, 38.6280, 25.3318, 38.0897, 33.2298, 25.7309, 40.5070, 26.3500,\n",
      "        34.8774, 30.4061, 30.8587, 38.4566, 29.2454, 30.7439, 34.3718, 31.3045,\n",
      "        34.7554, 25.8451, 34.4516, 29.8817, 25.0238, 35.7214, 25.5263, 34.2921,\n",
      "        27.6226, 29.2645, 40.6179, 23.1500, 38.1664, 32.0481, 25.0463, 41.3517,\n",
      "        22.7777, 39.5680, 34.4559, 27.4634, 34.0815, 23.9261, 35.0458, 32.9707,\n",
      "        26.9713, 35.0723, 26.8219, 33.4675, 27.3277, 29.8657, 36.8753, 27.3208,\n",
      "        32.4830, 29.5024, 26.2046, 40.7548, 23.8217, 38.6697, 30.0110, 20.4669,\n",
      "        38.2064, 20.0070, 33.6457, 30.5992, 29.9100, 41.2734, 25.4610, 37.7624,\n",
      "        30.2979, 30.5386, 41.5499, 27.4605, 31.8736, 30.4347, 26.6987, 36.9591],\n",
      "       device='cuda:0')\n",
      "tensor([28.6647, 33.7771, 30.8297, 26.1920, 37.2349, 22.1958, 40.1617, 23.8646,\n",
      "        30.3030, 37.6175, 25.3539, 37.1051, 26.2893, 27.4369, 38.2938, 19.4628,\n",
      "        33.0944, 30.6701, 26.2642, 34.5083, 26.7415, 38.6326, 31.5370, 24.7241,\n",
      "        36.2476, 24.5748, 30.7943, 27.1417, 26.1520, 38.9264, 24.7804, 34.5055,\n",
      "        27.8081, 34.1135, 33.0762, 28.1730, 39.0989, 30.2885, 25.6206, 36.7191,\n",
      "        22.0160, 37.4300, 26.4427, 26.2944, 37.8319, 22.2111, 36.2036, 28.3697,\n",
      "        26.0551, 39.0857, 24.2064, 32.1506, 33.2219, 30.1717, 31.4831, 27.5775,\n",
      "        31.1823, 26.8256, 24.7222, 28.5772, 28.3907, 42.9492, 24.8194, 31.8911,\n",
      "        37.9581, 22.6663, 36.5941, 27.6358, 33.3060, 37.4050, 22.5016, 40.2579,\n",
      "        34.9055, 24.9475, 36.3019, 19.8485, 37.4923, 34.6698, 28.3726, 37.3526,\n",
      "        26.4358, 38.5773, 23.5011, 25.2657, 37.1592, 26.5228, 35.8970, 28.1351,\n",
      "        27.9438, 37.3608, 23.0288, 36.6272, 29.6169, 27.2690, 41.5527, 24.6608,\n",
      "        38.5049, 30.4079, 29.6925, 42.2579, 23.6457, 35.1631, 30.4932, 27.6084,\n",
      "        37.4493, 27.5272, 30.0957, 38.5720, 23.8400, 39.9373, 26.3231, 29.5085,\n",
      "        30.4950, 20.5622, 34.5980, 21.8973, 37.5721, 27.8414, 33.2064, 41.0268,\n",
      "        23.9534, 32.2890, 27.2671, 30.4309, 33.9289, 20.7031, 35.8364, 34.7979,\n",
      "        24.9476, 38.6280, 25.3318, 38.0897, 33.2298, 25.7309, 40.5070, 26.3500,\n",
      "        34.8774, 30.4061, 30.8587, 38.4566, 29.2454, 30.7439, 34.3718, 31.3045,\n",
      "        34.7554, 25.8451, 34.4516, 29.8817, 25.0238, 35.7214, 25.5263, 34.2921,\n",
      "        27.6226, 29.2645, 40.6179, 23.1500, 38.1664, 32.0481, 25.0463, 41.3517,\n",
      "        22.7777, 39.5680, 34.4559, 27.4634, 34.0815, 23.9261, 35.0458, 32.9707,\n",
      "        26.9713, 35.0723, 26.8219, 33.4675, 27.3277, 29.8657, 36.8753, 27.3208,\n",
      "        32.4830, 29.5024, 26.2046, 40.7548, 23.8217, 38.6697, 30.0110, 20.4669,\n",
      "        38.2064, 20.0070, 33.6457, 30.5992, 29.9100, 41.2734, 25.4610, 37.7624,\n",
      "        30.2979, 30.5386, 41.5499, 27.4605, 31.8736, 30.4347, 26.6987, 36.9591],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(emb.weight.grad)\n",
    "print(weight_grad)\n",
    "assert((emb.weight.grad - weight_grad).sum().abs().item() < 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "cuda",
   "display_name": "cuda",
   "metadata": {
    "interpreter": {
     "hash": "1d7dd54100e9f16e1e28e492b2bae0030dfb6d1e38235cd6e826025fb0d5fab1"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}