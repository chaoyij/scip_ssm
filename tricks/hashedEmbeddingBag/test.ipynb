{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import hashed_embedding_bag_cpp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "bag_num = 18\n",
    "\n",
    "num_categories = 100\n",
    "num_feature = 200\n",
    "\n",
    "hashed_weight_size = 200"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "hashed_weights = torch.rand(hashed_weight_size)\n",
    "#hashed_weights = torch.arange(start=0, end=hashed_weight_size, dtype=torch.float)\n",
    "bag_size = torch.randint(low=0, high=7, size=(bag_num,))\n",
    "indices_num = bag_size.sum().item()\n",
    "\n",
    "indices = torch.randint(low=0, high=num_categories - 1, size=(indices_num, ))\n",
    "offsets = torch.cat([torch.zeros(1, dtype=torch.long), bag_size.cumsum(dim=0)[:-1]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.5662e-01, 1.0297e-01, 2.1181e-01, 6.5636e-01, 7.2786e-01, 4.5157e-01,\n",
      "        2.0752e-01, 8.0471e-01, 1.8861e-01, 6.4456e-01, 2.6018e-01, 4.1238e-01,\n",
      "        6.2257e-01, 7.9760e-01, 8.5013e-01, 5.6623e-02, 8.1732e-01, 4.5928e-01,\n",
      "        7.5461e-01, 3.1972e-01, 2.1896e-01, 9.6684e-02, 4.3134e-01, 3.9034e-01,\n",
      "        9.0840e-01, 1.4334e-01, 2.8215e-01, 1.5021e-01, 1.3907e-01, 8.8372e-01,\n",
      "        6.3072e-01, 2.1388e-01, 7.0158e-01, 7.0886e-01, 5.1800e-01, 2.0682e-01,\n",
      "        1.7585e-01, 2.1625e-01, 3.8375e-01, 5.8122e-01, 7.3864e-02, 7.7947e-01,\n",
      "        6.0129e-01, 7.4164e-01, 4.0878e-02, 7.6576e-01, 8.7189e-01, 1.4790e-01,\n",
      "        2.9183e-01, 1.2545e-01, 4.5613e-01, 2.9733e-01, 1.9096e-01, 7.3932e-01,\n",
      "        9.5027e-01, 4.4285e-01, 5.3704e-01, 6.1191e-01, 2.2574e-01, 2.8028e-01,\n",
      "        1.0100e-01, 4.0331e-01, 3.5373e-01, 5.9893e-01, 2.1979e-02, 3.6781e-01,\n",
      "        6.1164e-01, 1.8204e-01, 2.8697e-01, 4.5262e-01, 8.8963e-01, 5.0385e-01,\n",
      "        6.9111e-01, 1.6147e-01, 5.2234e-01, 5.2365e-01, 2.7282e-01, 7.6881e-01,\n",
      "        5.1500e-01, 4.1160e-01, 9.3479e-01, 4.4963e-02, 7.9410e-01, 2.2791e-01,\n",
      "        6.4402e-01, 1.6630e-01, 8.7426e-01, 5.5755e-01, 3.4148e-02, 3.5380e-01,\n",
      "        8.3468e-01, 2.3492e-01, 3.5123e-01, 4.5579e-01, 5.9958e-02, 8.0385e-01,\n",
      "        1.2775e-01, 8.3934e-01, 7.2682e-01, 5.1217e-01, 5.3436e-02, 3.4395e-01,\n",
      "        9.0404e-01, 4.9423e-01, 7.7626e-02, 1.6487e-01, 4.5824e-02, 1.9227e-01,\n",
      "        1.8573e-01, 5.2649e-01, 4.8045e-01, 2.3630e-01, 7.9080e-01, 8.5069e-01,\n",
      "        9.0580e-01, 9.9124e-01, 5.0120e-01, 7.5921e-01, 3.7554e-01, 8.4112e-01,\n",
      "        3.8079e-01, 4.5935e-01, 5.1695e-04, 6.6343e-01, 4.9054e-01, 3.1741e-01,\n",
      "        4.3433e-01, 8.4637e-01, 6.1655e-01, 9.1282e-01, 7.3281e-01, 8.3435e-01,\n",
      "        5.2384e-01, 9.9517e-02, 1.4971e-03, 6.9633e-01, 9.4287e-02, 5.1408e-01,\n",
      "        3.9501e-01, 1.0190e-01, 6.8185e-01, 9.5712e-01, 6.0360e-01, 4.7488e-01,\n",
      "        9.6887e-01, 1.9053e-01, 1.0579e-01, 5.6493e-01, 1.7588e-01, 4.5292e-01,\n",
      "        9.8902e-02, 1.6929e-01, 8.3133e-01, 8.9870e-01, 9.4500e-01, 6.0449e-02,\n",
      "        9.0557e-01, 9.7270e-01, 4.2422e-01, 3.0100e-01, 2.4162e-01, 4.8255e-01,\n",
      "        2.7593e-01, 8.0857e-01, 5.7112e-01, 3.9499e-01, 5.0671e-01, 2.8346e-02,\n",
      "        8.1199e-01, 8.6087e-01, 3.0015e-02, 7.2588e-01, 5.7049e-01, 6.6915e-02,\n",
      "        7.1965e-02, 9.8539e-01, 3.3470e-01, 4.1996e-01, 8.4029e-01, 5.3610e-01,\n",
      "        3.2471e-01, 7.4261e-01, 6.0345e-01, 5.3365e-01, 6.9823e-02, 9.3209e-01,\n",
      "        7.5152e-01, 6.2716e-01, 9.9687e-01, 5.5405e-01, 3.6227e-01, 7.9354e-01,\n",
      "        6.2967e-01, 9.7683e-01, 3.6135e-01, 6.1645e-01, 3.7602e-01, 7.6917e-01,\n",
      "        5.0490e-01, 1.6701e-01])\n"
     ]
    }
   ],
   "source": [
    "print(hashed_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 0, 2, 1, 6, 3, 6, 6, 2, 6, 6, 4, 0, 4, 1, 2, 2, 6])\n",
      "tensor([ 8, 93, 35, 20,  5, 67, 50, 46, 68, 38, 94, 91, 97,  5, 69, 95,  5, 32,\n",
      "        79, 10, 90, 51, 33,  5, 45, 15, 43, 97, 24, 69, 41, 86, 24, 40, 96, 59,\n",
      "        39, 82, 41, 14, 98, 18, 36, 79, 25, 88, 26, 25, 11, 11, 88, 25, 56, 46,\n",
      "        70,  5, 15, 75, 61, 27, 42,  7])\n",
      "tensor([ 0,  5,  5,  7,  8, 14, 17, 23, 29, 31, 37, 43, 47, 47, 51, 52, 54, 56])\n",
      "62\n"
     ]
    }
   ],
   "source": [
    "print(bag_size)\n",
    "print(indices)\n",
    "print(offsets)\n",
    "print(indices_num)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([62])\n"
     ]
    }
   ],
   "source": [
    "print(indices.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "mode = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "device = torch.cuda.current_device()\n",
    "hashed_weights = hashed_weights.to(device)\n",
    "indices = indices.to(device)\n",
    "offsets = offsets.to(device)\n",
    "\n",
    "output, offset2bag, bag_size, max_indices, hashed_idx = \\\n",
    "    hashed_embedding_bag_cpp.forward(hashed_weights, indices, offsets, mode, num_feature)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output is:\n",
      "tensor([[2.5495, 2.7259, 1.3040,  ..., 3.4254, 1.7057, 2.5805],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.9922, 0.9763, 0.7865,  ..., 1.2281, 0.8871, 0.9155],\n",
      "        ...,\n",
      "        [1.5951, 1.4250, 1.3399,  ..., 0.4097, 1.1818, 0.5418],\n",
      "        [0.5286, 1.2501, 0.1428,  ..., 0.5515, 1.3254, 1.3089],\n",
      "        [3.6974, 3.6964, 3.7366,  ..., 2.8123, 2.9436, 1.4833]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"output is:\")\n",
    "print(output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offset2bag is:\n",
      "tensor([ 0,  0,  0,  0,  0,  2,  2,  3,  4,  4,  4,  4,  4,  4,  5,  5,  5,  6,\n",
      "         6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  8,  8,  9,  9,  9,  9,  9,\n",
      "         9, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 13, 13, 13, 13, 14, 15, 15,\n",
      "        16, 16, 17, 17, 17, 17, 17, 17], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"offset2bag is:\")\n",
    "print(offset2bag)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag_size is:\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"bag_size is:\")\n",
    "print(bag_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_indices is:\n",
      "tensor([], device='cuda:0', size=(0, 0), dtype=torch.int64)\n"
     ]
    }
   ],
   "source": [
    "print(\"max_indices is:\")\n",
    "print(max_indices)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hashed_idx is:\n",
      "tensor([[ 96, 123, 150,  ..., 112, 139, 167],\n",
      "        [141, 168, 195,  ..., 157, 184,  12],\n",
      "        [195,  22,  49,  ...,  11,  38,  66],\n",
      "        ...,\n",
      "        [ 99, 126, 153,  ..., 115, 142, 170],\n",
      "        [154, 181,   8,  ..., 170, 197,  25],\n",
      "        [159, 186,  13,  ..., 175,   2,  30]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"hashed_idx is:\")\n",
    "print(hashed_idx)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([62, 200])\n"
     ]
    }
   ],
   "source": [
    "print(hashed_idx.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def toSignedInt(value, bits):\n",
    "    valueUint8 = value & (2**bits - 1)\n",
    "    if valueUint8 & 2**(bits-1):\n",
    "       return valueUint8 - 2**bits\n",
    "    return valueUint8\n",
    "\"\"\"\n",
    "def hash_function(a, b):\n",
    "    tmp1 = toSignedInt(a * 9824516537, 64)\n",
    "    tmp2 = toSignedInt(b * 57857966300227, 64)\n",
    "    tmp3 = toSignedInt(tmp1 + tmp2, 64)\n",
    "    tmp3 %= 117130198221199\n",
    "    return tmp3\n",
    "\"\"\"\n",
    "def hash_function(a, b):\n",
    "    return a + b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "hashed_weights = hashed_weights.to(device)\n",
    "indices = indices.to(device)\n",
    "offsets = offsets.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "output = output.to(device)\n",
    "offset2bag = offset2bag.to(device)\n",
    "bag_size = bag_size.to(device)\n",
    "max_indices = max_indices.to(device)\n",
    "hashed_idx = hashed_idx.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def make_offset2bag(offsets, indices):\n",
    "    offsets2bag = torch.zeros(indices.size(0) + 1, dtype=indices.dtype, device=offsets.device)\n",
    "    offsets2bag.index_add_(0, offsets, torch.ones_like(offsets, memory_format=torch.legacy_contiguous_format))\n",
    "    offsets2bag[0] -= 1\n",
    "    offsets2bag = offsets2bag.cumsum(0)\n",
    "    offsets2bag.resize_(indices.size(0))\n",
    "    return offsets2bag"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "expected_offsets2bag = make_offset2bag(offsets, indices)\n",
    "assert((expected_offsets2bag - offset2bag).abs().sum().item() == 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "expected_hashed_index = torch.zeros((indices_num, num_feature), dtype=torch.long)\n",
    "expected_output = torch.zeros(bag_num, num_feature)\n",
    "for i in range(indices.size(0)):\n",
    "    for j in range(num_feature):\n",
    "        weight_idx = hashed_embedding_bag_cpp.hash(indices[i].item(), j) % hashed_weights.size(0)\n",
    "        expected_hashed_index[i, j] = weight_idx\n",
    "        expected_output[expected_offsets2bag[i].item(), j] += hashed_weights[weight_idx]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.5495, 2.7259, 1.3040,  ..., 3.4254, 1.7057, 2.5805],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.9922, 0.9763, 0.7865,  ..., 1.2281, 0.8871, 0.9155],\n",
      "        ...,\n",
      "        [1.5951, 1.4250, 1.3399,  ..., 0.4097, 1.1818, 0.5418],\n",
      "        [0.5286, 1.2501, 0.1428,  ..., 0.5515, 1.3254, 1.3089],\n",
      "        [3.6974, 3.6964, 3.7366,  ..., 2.8123, 2.9436, 1.4833]])\n"
     ]
    }
   ],
   "source": [
    "print(expected_output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "assert(expected_hashed_index.equal(hashed_idx))\n",
    "assert(expected_output.equal(output))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "output_grad = torch.rand_like(expected_output)\n",
    "#output_grad = torch.arange(start=0, end=num_feature, dtype=torch.float).unsqueeze(0).repeat(bag_num, 1)\n",
    "#output_grad = torch.arange(start=0, end=bag_num, dtype=torch.float).unsqueeze(-1).repeat(1, num_feature)\n",
    "\n",
    "output_grad[:, 0] = 0.5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "expected_weight_grad = torch.zeros_like(hashed_weights)\n",
    "for i in range(indices.size(0)):\n",
    "    for j in range(num_feature):\n",
    "        weight_idx = hashed_embedding_bag_cpp.hash(indices[i].item(), j) % hashed_weights.size(0)\n",
    "        expected_weight_grad[weight_idx] += output_grad[offset2bag[i].item(), j]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "device = torch.cuda.current_device()\n",
    "hashed_weights = hashed_weights.to(device)\n",
    "indices = indices.to(device)\n",
    "offsets = offsets.to(device)\n",
    "offset2bag = offset2bag.to(device)\n",
    "bag_size = bag_size.to(device)\n",
    "max_indices = max_indices.to(device)\n",
    "hashed_idx = hashed_idx.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000, 0.3796, 0.1999,  ..., 0.8967, 0.4053, 0.3665],\n",
      "        [0.5000, 0.5629, 0.7411,  ..., 0.2909, 0.3786, 0.4533],\n",
      "        [0.5000, 0.0049, 0.9356,  ..., 0.9679, 0.2347, 0.5655],\n",
      "        ...,\n",
      "        [0.5000, 0.7635, 0.6262,  ..., 0.0303, 0.6782, 0.6878],\n",
      "        [0.5000, 0.8902, 0.3326,  ..., 0.4067, 0.1555, 0.5696],\n",
      "        [0.5000, 0.8377, 0.9889,  ..., 0.5755, 0.1353, 0.7145]])\n"
     ]
    }
   ],
   "source": [
    "print(output_grad)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "output_grad = output_grad.to(device)\n",
    "weight_grad = hashed_embedding_bag_cpp.backward(\n",
    "    output_grad, indices, offsets, offset2bag, bag_size, max_indices, hashed_idx, hashed_weights.size(0), False, mode, num_feature)\n",
    "weight_grad = weight_grad.cpu()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([27.8060, 37.2749, 28.3390, 28.5040, 35.0896, 27.6691, 34.2967, 27.0006,\n",
      "        30.2893, 34.8951, 25.1916, 34.3260, 31.2380, 32.2958, 34.8828, 21.5368,\n",
      "        39.0195, 34.7657, 29.3103, 37.0372, 21.9624, 34.5258, 30.2695, 22.3308,\n",
      "        34.0931, 25.3380, 35.0010, 31.4020, 30.9855, 35.7121, 23.6572, 34.4090,\n",
      "        30.6626, 28.6800, 35.8291, 26.2544, 37.2066, 31.3558, 22.1169, 35.4397,\n",
      "        25.3396, 37.4082, 30.6223, 24.3011, 41.3767, 22.6265, 36.7866, 28.8963,\n",
      "        30.2614, 35.3792, 26.4805, 35.5263, 31.8480, 31.5340, 34.0558, 26.2993,\n",
      "        39.1861, 32.6980, 24.8585, 35.9554, 23.3136, 36.0605, 24.9011, 29.2936,\n",
      "        36.0588, 23.2527, 38.1848, 31.1847, 31.3241, 31.9540, 21.9563, 36.2847,\n",
      "        30.9544, 28.8849, 40.6494, 23.8575, 36.7806, 34.8625, 25.3975, 39.7284,\n",
      "        26.2064, 33.7832, 29.0906, 27.0842, 38.3097, 28.1572, 33.3044, 28.9422,\n",
      "        31.1652, 36.7883, 25.9017, 38.4808, 30.6941, 29.1514, 31.3988, 23.5577,\n",
      "        36.9976, 29.1644, 26.5245, 44.7776, 27.1320, 30.2892, 28.6679, 29.2324,\n",
      "        37.4697, 27.0237, 32.0631, 35.6686, 27.0862, 40.3855, 27.0951, 35.5679,\n",
      "        34.0682, 25.4618, 38.7873, 26.0358, 35.7680, 27.4661, 31.7194, 35.4445,\n",
      "        23.2392, 33.2253, 26.9505, 33.0043, 38.0638, 24.6197, 40.3498, 34.4331,\n",
      "        27.9554, 41.9891, 26.0736, 37.5773, 31.3720, 23.5051, 41.4220, 24.0120,\n",
      "        33.3336, 29.4280, 27.9892, 35.7598, 23.4103, 27.7966, 30.5937, 30.8462,\n",
      "        41.1075, 27.7033, 35.1143, 28.0072, 29.0478, 34.6967, 27.4507, 39.2261,\n",
      "        28.9365, 28.2865, 41.8878, 19.0507, 36.6099, 29.7332, 32.4363, 43.2884,\n",
      "        24.6262, 39.5793, 36.4166, 26.4000, 33.6701, 26.2051, 38.4433, 29.2947,\n",
      "        29.2568, 34.3336, 28.9797, 37.0151, 27.7556, 30.4351, 36.6578, 28.2359,\n",
      "        34.5474, 29.0942, 28.8511, 34.3673, 28.3465, 38.2725, 29.9358, 24.8990,\n",
      "        39.0412, 22.8657, 38.9930, 28.5912, 28.1242, 39.9085, 25.1167, 32.4467,\n",
      "        24.4247, 23.9481, 37.2743, 23.6502, 33.7267, 29.1793, 29.5506, 35.3736])\n",
      "tensor([27.8060, 37.2749, 28.3390, 28.5040, 35.0896, 27.6691, 34.2967, 27.0006,\n",
      "        30.2893, 34.8951, 25.1916, 34.3260, 31.2380, 32.2958, 34.8828, 21.5368,\n",
      "        39.0195, 34.7657, 29.3103, 37.0372, 21.9624, 34.5258, 30.2695, 22.3308,\n",
      "        34.0931, 25.3380, 35.0010, 31.4020, 30.9855, 35.7121, 23.6572, 34.4090,\n",
      "        30.6626, 28.6800, 35.8291, 26.2544, 37.2066, 31.3558, 22.1169, 35.4397,\n",
      "        25.3396, 37.4082, 30.6223, 24.3011, 41.3767, 22.6265, 36.7866, 28.8963,\n",
      "        30.2614, 35.3792, 26.4805, 35.5263, 31.8480, 31.5340, 34.0558, 26.2993,\n",
      "        39.1861, 32.6980, 24.8585, 35.9554, 23.3136, 36.0605, 24.9011, 29.2936,\n",
      "        36.0588, 23.2527, 38.1848, 31.1847, 31.3241, 31.9540, 21.9563, 36.2847,\n",
      "        30.9544, 28.8849, 40.6494, 23.8575, 36.7806, 34.8625, 25.3975, 39.7284,\n",
      "        26.2064, 33.7832, 29.0906, 27.0842, 38.3097, 28.1572, 33.3044, 28.9422,\n",
      "        31.1652, 36.7883, 25.9017, 38.4808, 30.6941, 29.1514, 31.3988, 23.5577,\n",
      "        36.9976, 29.1644, 26.5245, 44.7776, 27.1320, 30.2892, 28.6679, 29.2324,\n",
      "        37.4697, 27.0237, 32.0631, 35.6686, 27.0862, 40.3855, 27.0951, 35.5679,\n",
      "        34.0682, 25.4618, 38.7873, 26.0358, 35.7680, 27.4661, 31.7194, 35.4445,\n",
      "        23.2392, 33.2253, 26.9505, 33.0043, 38.0638, 24.6197, 40.3498, 34.4331,\n",
      "        27.9554, 41.9891, 26.0736, 37.5773, 31.3720, 23.5051, 41.4220, 24.0120,\n",
      "        33.3336, 29.4280, 27.9892, 35.7598, 23.4103, 27.7966, 30.5937, 30.8462,\n",
      "        41.1075, 27.7033, 35.1143, 28.0072, 29.0478, 34.6967, 27.4507, 39.2261,\n",
      "        28.9365, 28.2865, 41.8878, 19.0507, 36.6099, 29.7332, 32.4363, 43.2884,\n",
      "        24.6262, 39.5793, 36.4166, 26.4000, 33.6701, 26.2051, 38.4433, 29.2947,\n",
      "        29.2568, 34.3336, 28.9797, 37.0151, 27.7556, 30.4351, 36.6578, 28.2359,\n",
      "        34.5474, 29.0942, 28.8511, 34.3673, 28.3465, 38.2725, 29.9358, 24.8990,\n",
      "        39.0412, 22.8657, 38.9930, 28.5912, 28.1242, 39.9085, 25.1167, 32.4467,\n",
      "        24.4247, 23.9481, 37.2743, 23.6502, 33.7267, 29.1793, 29.5506, 35.3736])\n"
     ]
    }
   ],
   "source": [
    "print(expected_weight_grad)\n",
    "print(weight_grad)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "assert((weight_grad - expected_weight_grad).sum().item() < 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "import hashedEmbeddingBag\n",
    "\n",
    "emb = hashedEmbeddingBag.HashedEmbeddingBag(\n",
    "    num_categories, num_feature, hashed_weight_size / (num_feature * num_categories), \"sum\", hashed_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "res = emb(indices, offsets)\n",
    "res.retain_grad()\n",
    "tmp = res * torch.rand_like(res)\n",
    "y = tmp.sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "y.backward()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.8299, 0.3449, 0.4369,  ..., 0.2575, 0.6161, 0.2326],\n        [0.2031, 0.6160, 0.0304,  ..., 0.4137, 0.8672, 0.9687],\n        [0.5426, 0.2544, 0.4731,  ..., 0.1255, 0.5904, 0.2212],\n        ...,\n        [0.5786, 0.1521, 0.6528,  ..., 0.0132, 0.9859, 0.4594],\n        [0.3869, 0.1114, 0.4772,  ..., 0.5867, 0.7003, 0.6562],\n        [0.6193, 0.5987, 0.6355,  ..., 0.7297, 0.5350, 0.3156]],\n       device='cuda:0')"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.grad"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "assert(res.cpu().equal(expected_output))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "output_grad = res.grad\n",
    "weight_grad = hashed_embedding_bag_cpp.backward(\n",
    "    output_grad, indices, offsets, offset2bag, bag_size, max_indices, hashed_idx, hashed_weights.size(0), False, mode, num_feature)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([28.6647, 33.7771, 30.8297, 26.1920, 37.2349, 22.1958, 40.1617, 23.8646,\n",
      "        30.3030, 37.6175, 25.3539, 37.1051, 26.2893, 27.4369, 38.2938, 19.4628,\n",
      "        33.0944, 30.6701, 26.2642, 34.5083, 26.7415, 38.6326, 31.5370, 24.7241,\n",
      "        36.2476, 24.5748, 30.7943, 27.1417, 26.1520, 38.9264, 24.7804, 34.5055,\n",
      "        27.8081, 34.1135, 33.0762, 28.1730, 39.0989, 30.2885, 25.6206, 36.7191,\n",
      "        22.0160, 37.4300, 26.4427, 26.2944, 37.8319, 22.2111, 36.2036, 28.3697,\n",
      "        26.0551, 39.0857, 24.2064, 32.1506, 33.2219, 30.1717, 31.4831, 27.5775,\n",
      "        31.1823, 26.8256, 24.7222, 28.5772, 28.3907, 42.9492, 24.8194, 31.8911,\n",
      "        37.9581, 22.6663, 36.5941, 27.6358, 33.3060, 37.4050, 22.5016, 40.2579,\n",
      "        34.9055, 24.9475, 36.3019, 19.8485, 37.4923, 34.6698, 28.3726, 37.3526,\n",
      "        26.4358, 38.5773, 23.5011, 25.2657, 37.1592, 26.5228, 35.8970, 28.1351,\n",
      "        27.9438, 37.3608, 23.0288, 36.6272, 29.6169, 27.2690, 41.5527, 24.6608,\n",
      "        38.5049, 30.4079, 29.6925, 42.2579, 23.6457, 35.1631, 30.4932, 27.6084,\n",
      "        37.4493, 27.5272, 30.0957, 38.5720, 23.8400, 39.9373, 26.3231, 29.5085,\n",
      "        30.4950, 20.5622, 34.5980, 21.8973, 37.5721, 27.8414, 33.2064, 41.0268,\n",
      "        23.9534, 32.2890, 27.2671, 30.4309, 33.9289, 20.7031, 35.8364, 34.7979,\n",
      "        24.9476, 38.6280, 25.3318, 38.0897, 33.2298, 25.7309, 40.5070, 26.3500,\n",
      "        34.8774, 30.4061, 30.8587, 38.4566, 29.2454, 30.7439, 34.3718, 31.3045,\n",
      "        34.7554, 25.8451, 34.4516, 29.8817, 25.0238, 35.7214, 25.5263, 34.2921,\n",
      "        27.6226, 29.2645, 40.6179, 23.1500, 38.1664, 32.0481, 25.0463, 41.3517,\n",
      "        22.7777, 39.5680, 34.4559, 27.4634, 34.0815, 23.9261, 35.0458, 32.9707,\n",
      "        26.9713, 35.0723, 26.8219, 33.4675, 27.3277, 29.8657, 36.8753, 27.3208,\n",
      "        32.4830, 29.5024, 26.2046, 40.7548, 23.8217, 38.6697, 30.0110, 20.4669,\n",
      "        38.2064, 20.0070, 33.6457, 30.5992, 29.9100, 41.2734, 25.4610, 37.7624,\n",
      "        30.2979, 30.5386, 41.5499, 27.4605, 31.8736, 30.4347, 26.6987, 36.9591],\n",
      "       device='cuda:0')\n",
      "tensor([28.6647, 33.7771, 30.8297, 26.1920, 37.2349, 22.1958, 40.1617, 23.8646,\n",
      "        30.3030, 37.6175, 25.3539, 37.1051, 26.2893, 27.4369, 38.2938, 19.4628,\n",
      "        33.0944, 30.6701, 26.2642, 34.5083, 26.7415, 38.6326, 31.5370, 24.7241,\n",
      "        36.2476, 24.5748, 30.7943, 27.1417, 26.1520, 38.9264, 24.7804, 34.5055,\n",
      "        27.8081, 34.1135, 33.0762, 28.1730, 39.0989, 30.2885, 25.6206, 36.7191,\n",
      "        22.0160, 37.4300, 26.4427, 26.2944, 37.8319, 22.2111, 36.2036, 28.3697,\n",
      "        26.0551, 39.0857, 24.2064, 32.1506, 33.2219, 30.1717, 31.4831, 27.5775,\n",
      "        31.1823, 26.8256, 24.7222, 28.5772, 28.3907, 42.9492, 24.8194, 31.8911,\n",
      "        37.9581, 22.6663, 36.5941, 27.6358, 33.3060, 37.4050, 22.5016, 40.2579,\n",
      "        34.9055, 24.9475, 36.3019, 19.8485, 37.4923, 34.6698, 28.3726, 37.3526,\n",
      "        26.4358, 38.5773, 23.5011, 25.2657, 37.1592, 26.5228, 35.8970, 28.1351,\n",
      "        27.9438, 37.3608, 23.0288, 36.6272, 29.6169, 27.2690, 41.5527, 24.6608,\n",
      "        38.5049, 30.4079, 29.6925, 42.2579, 23.6457, 35.1631, 30.4932, 27.6084,\n",
      "        37.4493, 27.5272, 30.0957, 38.5720, 23.8400, 39.9373, 26.3231, 29.5085,\n",
      "        30.4950, 20.5622, 34.5980, 21.8973, 37.5721, 27.8414, 33.2064, 41.0268,\n",
      "        23.9534, 32.2890, 27.2671, 30.4309, 33.9289, 20.7031, 35.8364, 34.7979,\n",
      "        24.9476, 38.6280, 25.3318, 38.0897, 33.2298, 25.7309, 40.5070, 26.3500,\n",
      "        34.8774, 30.4061, 30.8587, 38.4566, 29.2454, 30.7439, 34.3718, 31.3045,\n",
      "        34.7554, 25.8451, 34.4516, 29.8817, 25.0238, 35.7214, 25.5263, 34.2921,\n",
      "        27.6226, 29.2645, 40.6179, 23.1500, 38.1664, 32.0481, 25.0463, 41.3517,\n",
      "        22.7777, 39.5680, 34.4559, 27.4634, 34.0815, 23.9261, 35.0458, 32.9707,\n",
      "        26.9713, 35.0723, 26.8219, 33.4675, 27.3277, 29.8657, 36.8753, 27.3208,\n",
      "        32.4830, 29.5024, 26.2046, 40.7548, 23.8217, 38.6697, 30.0110, 20.4669,\n",
      "        38.2064, 20.0070, 33.6457, 30.5992, 29.9100, 41.2734, 25.4610, 37.7624,\n",
      "        30.2979, 30.5386, 41.5499, 27.4605, 31.8736, 30.4347, 26.6987, 36.9591],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(emb.weight.grad)\n",
    "print(weight_grad)\n",
    "assert((emb.weight.grad - weight_grad).sum().abs().item() < 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python38564bitpytorch16conda449c99c102334cb58c1649ad5fb9029b",
   "language": "python",
   "display_name": "Python 3.8.5 64-bit ('pytorch1.6': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}